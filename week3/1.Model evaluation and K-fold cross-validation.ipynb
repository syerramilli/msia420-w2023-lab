{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-evaluation and K-fold cross-validation\n",
    "\n",
    "In this notebook, we will be using K-fold cross-validation to estimate generalization performance of two different logistic regression models. scikit-learn has two useful modules:\n",
    "\n",
    "1. `sklearn.metrics`:\n",
    "2. `sklearn.model_selection`: \n",
    "\n",
    "## Data - car marketing study\n",
    "\n",
    "Notes 1 slide 6\n",
    "\n",
    "The data in `Car.csv` are car purchasing behavior for n = 33 households from a marketing survey. The response is binary (1 if a household purchased a car; 0 otherwise).\n",
    "\n",
    "**Attribute information**:\n",
    "    \n",
    "    1. y: Binary response variable\n",
    "    2. income: Household income (thousands)\n",
    "    3. car_age: Age of oldest automobile\n",
    "    \n",
    "Compare two different logistic regression models:\n",
    "\n",
    "1. no interaction term\n",
    "$$\n",
    "    \\log\\left(\\frac{p(\\mathbf{x})}{1-p(\\mathbf{x})}\\right) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\n",
    "$$\n",
    "2. with an interaction term\n",
    "\n",
    "$$\n",
    "    \\log\\left(\\frac{p(\\mathbf{x})}{1-p(\\mathbf{x})}\\right) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1x_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import log_loss # negative log-likelihood\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>income</th>\n",
       "      <th>car_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  income  car_age\n",
       "0  0      32        3\n",
       "1  0      45        2\n",
       "2  1      60        2\n",
       "3  0      53        1\n",
       "4  0      25        4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car = pd.read_csv('../data/Car.csv')\n",
    "car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car and income-age as predictors\n",
    "clf1 = smf.glm('y~income+car_age',data=car,family=sm.families.Binomial()).fit()\n",
    "\n",
    "# interaction term\n",
    "clf2 = smf.glm('y~income+car_age + income:car_age',data=car,family=sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Results: Generalized linear model\n",
      "=============================================================\n",
      "Model:              GLM              AIC:            42.6896 \n",
      "Link Function:      logit            BIC:            -68.2056\n",
      "Dependent Variable: y                Log-Likelihood: -18.345 \n",
      "Date:               2023-01-25 10:12 LL-Null:        -22.494 \n",
      "No. Observations:   33               Deviance:       36.690  \n",
      "Df Model:           2                Pearson chi2:   33.6    \n",
      "Df Residuals:       30               Scale:          1.0000  \n",
      "Method:             IRLS                                     \n",
      "-------------------------------------------------------------\n",
      "               Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
      "-------------------------------------------------------------\n",
      "Intercept     -4.7393   2.1019 -2.2547 0.0242 -8.8591 -0.6196\n",
      "income         0.0677   0.0281  2.4141 0.0158  0.0127  0.1227\n",
      "car_age        0.5986   0.3901  1.5347 0.1249 -0.1659  1.3631\n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf1.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.34481579484669 17.70205090961161\n"
     ]
    }
   ],
   "source": [
    "# negative log-likelihood - training set metric\n",
    "log_loss1 = clf1.deviance/2\n",
    "log_loss2 = clf2.deviance/2\n",
    "\n",
    "print(log_loss1,log_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2936251996876782, 1.315275812703734)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AICs - computed by statsmodels\n",
    "n = car.shape[0]\n",
    "clf1.aic/n,clf2.aic/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2936251996876782 1.315275812703734\n"
     ]
    }
   ],
   "source": [
    "# manually computing AICs\n",
    "aic1 = clf1.deviance/n + 2*3/n\n",
    "aic2 = clf2.deviance/n + 2*4/n\n",
    "print(aic1,aic2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross-validation\n",
    "\n",
    "We will be using the `KFold` class from scikit-learn's `model_selection` module to generate the KFold partitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train idx         Test idx\n",
      "[2 3 4 5 6 7 8 9] [0 1]\n",
      "[0 1 4 5 6 7 8 9] [2 3]\n",
      "[0 1 2 3 6 7 8 9] [4 5]\n",
      "[0 1 2 3 4 5 8 9] [6 7]\n",
      "[0 1 2 3 4 5 6 7] [8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# data with 10 entries\n",
    "Z = np.concatenate([np.zeros(5),np.ones(5)])\n",
    "\n",
    "# create K-fold object with 5 folds\n",
    "kf = KFold(n_splits=5) \n",
    "\n",
    "print('%-17s %-8s'%('Train idx','Test idx'))\n",
    "for train_index,test_index in kf.split(Z):\n",
    "    print(train_index,test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data                Test data\n",
      "[0. 0. 0. 1. 1. 1. 1. 1.] [0. 0.]\n",
      "[0. 0. 0. 1. 1. 1. 1. 1.] [0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 1. 1.] [0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1.] [1. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1.] [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('%-25s %-9s'%('Train data','Test data'))\n",
    "for train_index,test_index in kf.split(Z):\n",
    "    print(Z[train_index],Z[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KFold` does not re-arrange the data by default. Running it multiple times, we get the same folds partition. To re-arrange the data, pass `shuffle=True` and optionally pass a value to the `random_state` argument for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train             Test \n",
      "[0 1 2 3 4 5 7 9] [6 8]\n",
      "[1 2 3 4 5 6 7 8] [0 9]\n",
      "[0 1 3 4 6 7 8 9] [2 5]\n",
      "[0 2 3 4 5 6 8 9] [1 7]\n",
      "[0 1 2 5 6 7 8 9] [3 4]\n"
     ]
    }
   ],
   "source": [
    "# impact of shuffling\n",
    "# create K-fold object with 5 folds\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=8) \n",
    "\n",
    "print('%-17s %-5s'%('Train','Test'))\n",
    "for train_index,test_index in kf.split(Z):\n",
    "    print(train_index,test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train             Test \n",
      "[0 1 2 3 5 6 7 9] [4 8]\n",
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 2 3 4 5 6 7 8] [1 9]\n",
      "[1 2 4 5 6 7 8 9] [0 3]\n",
      "[0 1 2 3 4 7 8 9] [5 6]\n"
     ]
    }
   ],
   "source": [
    "# impact of shuffling\n",
    "# create K-fold object with 5 folds\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=9) \n",
    "\n",
    "print('%-17s %-5s'%('Train','Test'))\n",
    "for train_index,test_index in kf.split(Z):\n",
    "    print(train_index,test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL for model1: 0.712\n",
      "NLL for model2: 0.741\n"
     ]
    }
   ],
   "source": [
    "# create the KFold object\n",
    "kf = KFold(n_splits=10,random_state=1,shuffle=True)\n",
    "\n",
    "logloss1 = []\n",
    "logloss2 = []\n",
    "\n",
    "for train_index,test_index in kf.split(car):\n",
    "    \n",
    "    #### model with no interaction term ####\n",
    "    # fit model on the remaining folds\n",
    "    clf1 = (\n",
    "        smf.glm('y~income+car_age',data=car.loc[train_index,:],family=sm.families.Binomial())\n",
    "        .fit()\n",
    "    )\n",
    "    # obtain predictions on the held out fold and compute logistic loss\n",
    "    p_pred1 = clf1.predict(car.loc[test_index,:]) # returns probabilities\n",
    "    logloss1.append(log_loss(car['y'].loc[test_index],p_pred1,labels=[0,1]))\n",
    "    \n",
    "\n",
    "    #### model with interaction term ####\n",
    "    # fit model on the remaining folds\n",
    "    clf2 = (\n",
    "        smf.glm('y~income+car_age+income:car_age',data=car.loc[train_index,:],family=sm.families.Binomial())\n",
    "        .fit()\n",
    "    )\n",
    "    # obtain predictions on the held out fold and compute logistic loss\n",
    "    p_pred2 = clf2.predict(car.loc[test_index,:])\n",
    "    logloss2.append(log_loss(car['y'].loc[test_index],p_pred2,labels=[0,1]))\n",
    "\n",
    "# print CV estimate\n",
    "print('NLL for model1: %5.3f'%np.mean(logloss1))\n",
    "print('NLL for model2: %5.3f'%np.mean(logloss2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a different K-fold partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL for model1: 0.644\n",
      "NLL for model2: 0.650\n"
     ]
    }
   ],
   "source": [
    "# create the KFold object\n",
    "kf = KFold(n_splits=10,random_state=17,shuffle=True)\n",
    "\n",
    "logloss1 = []\n",
    "logloss2 = []\n",
    "\n",
    "for train_index,test_index in kf.split(car):\n",
    "    \n",
    "    #### model with no interaction term ####\n",
    "    # fit model on the remaining folds\n",
    "    clf1 = (\n",
    "        smf.glm('y~income+car_age',data=car.loc[train_index,:],family=sm.families.Binomial())\n",
    "        .fit()\n",
    "    )\n",
    "    # obtain predictions on the held out fold and compute logistic loss\n",
    "    p_pred1 = clf1.predict(car.loc[test_index,:]) # returns probabilities\n",
    "    logloss1.append(log_loss(car['y'].loc[test_index],p_pred1,labels=[0,1]))\n",
    "    \n",
    "\n",
    "    #### model with interaction term ####\n",
    "    # fit model on the remaining folds\n",
    "    clf2 = (\n",
    "        smf.glm('y~income+car_age+income:car_age',data=car.loc[train_index,:],family=sm.families.Binomial())\n",
    "        .fit()\n",
    "    )\n",
    "    # obtain predictions on the held out fold and compute logistic loss\n",
    "    p_pred2 = clf2.predict(car.loc[test_index,:])\n",
    "    logloss2.append(log_loss(car['y'].loc[test_index],p_pred2,labels=[0,1]))\n",
    "    \n",
    "# print CV estimate\n",
    "print('NLL for model1: %5.3f'%np.mean(logloss1))\n",
    "print('NLL for model2: %5.3f'%np.mean(logloss2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicated cross-validation\n",
    "\n",
    "For running replicating cross-validation, we could use a for loop to repeat the above calculations for different fold partitions. Alternatively, the `model_selection` module provides a `RepeatedKFold` class for generating multiple replicates.\n",
    "\n",
    "The for loop syntax using `RepeatedKFold` is exactly the same as when using `KFold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train idx         Test idx\n",
      "[0 1 3 4 5 6 7 8] [2 9]\n",
      "[0 1 2 3 5 7 8 9] [4 6]\n",
      "[1 2 4 5 6 7 8 9] [0 3]\n",
      "[0 2 3 4 5 6 8 9] [1 7]\n",
      "[0 1 2 3 4 6 7 9] [5 8]\n",
      "*****************\n",
      "[0 1 2 3 4 6 7 8] [5 9]\n",
      "[1 2 4 5 6 7 8 9] [0 3]\n",
      "[0 1 2 3 5 6 7 9] [4 8]\n",
      "[0 3 4 5 6 7 8 9] [1 2]\n",
      "[0 1 2 3 4 5 8 9] [6 7]\n",
      "*****************\n",
      "[0 1 2 4 5 6 7 9] [3 8]\n",
      "[0 1 2 3 4 6 7 8] [5 9]\n",
      "[1 2 3 4 5 7 8 9] [0 6]\n",
      "[0 2 3 4 5 6 8 9] [1 7]\n",
      "[0 1 3 5 6 7 8 9] [2 4]\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "# data with 10 entries\n",
    "Z = np.concatenate([np.zeros(5),np.ones(5)])\n",
    "\n",
    "# replicated k-fold with 3 replicates\n",
    "rkf = RepeatedKFold(n_splits=5,n_repeats=3,random_state=1) \n",
    "\n",
    "print('%-17s %-8s'%('Train idx','Test idx'))\n",
    "ct = 1\n",
    "for train_index,test_index in rkf.split(Z):\n",
    "    print(train_index,test_index)\n",
    "    if ct%5==0:\n",
    "        # demarcating replicates\n",
    "        print('*****************')\n",
    "    ct+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL for model1: 0.674\n",
      "NLL for model2: 0.716\n"
     ]
    }
   ],
   "source": [
    "# 5 replicates of 10 fold cross-validation\n",
    "rkf = RepeatedKFold(n_splits=10,n_repeats=5,random_state=1)\n",
    "\n",
    "logloss1 = []\n",
    "logloss2 = []\n",
    "\n",
    "for train_index,test_index in rkf.split(car):\n",
    "    \n",
    "    #### model with no interaction term ####\n",
    "    # fit model on the remaining folds\n",
    "    clf1 = (\n",
    "        smf.glm('y~income+car_age',data=car.loc[train_index,:],family=sm.families.Binomial())\n",
    "        .fit()\n",
    "    )\n",
    "    # obtain predictions on the held out fold and compute logistic loss\n",
    "    p_pred1 = clf1.predict(car.loc[test_index,:]) # returns probabilities\n",
    "    logloss1.append(log_loss(car['y'].loc[test_index],p_pred1,labels=[0,1]))\n",
    "    \n",
    "\n",
    "    #### model with interaction term ####\n",
    "    # fit model on the remaining folds\n",
    "    clf2 = (\n",
    "        smf.glm('y~income+car_age+income:car_age',data=car.loc[train_index,:],family=sm.families.Binomial())\n",
    "        .fit()\n",
    "    )\n",
    "    # obtain predictions on the held out fold and compute logistic loss\n",
    "    p_pred2 = clf2.predict(car.loc[test_index,:])\n",
    "    logloss2.append(log_loss(car['y'].loc[test_index],p_pred2,labels=[0,1]))\n",
    "\n",
    "# print CV estimate\n",
    "print('NLL for model1: %5.3f'%np.mean(logloss1))\n",
    "print('NLL for model2: %5.3f'%np.mean(logloss2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8824128186916258,\n",
       " 0.7423322543177083,\n",
       " 0.37163639827807765,\n",
       " 0.6895255662225539,\n",
       " 0.4876876616091002,\n",
       " 1.8723431643825992,\n",
       " 0.4446211590973837,\n",
       " 0.4557258794640511,\n",
       " 0.5123470365825539,\n",
       " 0.6621216843186849,\n",
       " 1.0528540322572453,\n",
       " 0.33241954849805,\n",
       " 0.7554616914557136,\n",
       " 0.3428810771412291,\n",
       " 0.5179831928014335,\n",
       " 0.7032840484619672,\n",
       " 0.3061130950311808,\n",
       " 0.6134716591258881,\n",
       " 0.6907315182914652,\n",
       " 1.1610794039990464,\n",
       " 0.8870478752079196,\n",
       " 0.4907311006143295,\n",
       " 1.1328871274355574,\n",
       " 0.4629217726195587,\n",
       " 0.3261367775725105,\n",
       " 0.5791864782577943,\n",
       " 1.0743292160533844,\n",
       " 0.28551487617950594,\n",
       " 0.7975733772118082,\n",
       " 0.8428034301655057,\n",
       " 0.7110524358838342,\n",
       " 1.4570610486867728,\n",
       " 0.6521643847452291,\n",
       " 0.3703127309454037,\n",
       " 0.39947136703210906,\n",
       " 0.2731829624709366,\n",
       " 0.6864666661821245,\n",
       " 0.734379212423702,\n",
       " 0.809411991186796,\n",
       " 0.3574360788565973,\n",
       " 0.9856668283250295,\n",
       " 0.8222474351472615,\n",
       " 0.6780182208678622,\n",
       " 0.5503576055835853,\n",
       " 0.5365426404107375,\n",
       " 0.26544053245049815,\n",
       " 0.6559343004452943,\n",
       " 0.924833621015595,\n",
       " 1.0271494978180955,\n",
       " 0.3170969290323187]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msia420-2",
   "language": "python",
   "name": "msia420-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
